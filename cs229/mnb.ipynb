{
 "metadata": {
  "name": "",
  "signature": "sha256:2f6ffaa545a07e881cdbcf017558ba2c42a3a031e3a475d59519ae74b9c341c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import svm\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn import cross_validation\n",
      "import pandas as pd\n",
      "import compute_stats as cs\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.gridspec as Gridspec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the test data\n",
      "test_data = pd.read_csv('test.csv')\n",
      "test_data = test_data.drop('Unnamed: 0',1)\n",
      "test_labels = test_data['label']\n",
      "test_labels[test_labels==1] = 0; test_labels[test_labels>1] = 1\n",
      "test_data = test_data.drop('label',1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the training data\n",
      "train_data = pd.read_csv('training.csv')\n",
      "train_data = train_data.drop('Unnamed: 0',1)\n",
      "train_labels = train_data['label']\n",
      "train_labels[train_labels==1] = 0; train_labels[train_labels>1] = 1\n",
      "train_data = train_data.drop('label',1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert the test and training data into integers for multinomialNB\n",
      "interval = np.arange(50,1050,50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interval"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([  50,  100,  150,  200,  250,  300,  350,  400,  450,  500,  550,\n",
        "        600,  650,  700,  750,  800,  850,  900,  950, 1000])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_proj = MultinomialNB()\n",
      "\n",
      "scores = []\n",
      "i = 0\n",
      "for num in interval:\n",
      "    # Fit to training data and test on test data for MNB\n",
      "    int_test = cs.convert_to_integers(pd.DataFrame.copy(test_data),num)\n",
      "    int_train = cs.convert_to_integers(pd.DataFrame.copy(train_data),num)\n",
      "    drop = True\n",
      "    if drop:\n",
      "        int_train = int_train.drop('intensity_r',1)\n",
      "        int_train = int_train.drop('percentile',1)\n",
      "        int_train = int_train.drop('reg_ratio',1)\n",
      "        int_test = int_test.drop('intensity_r',1)\n",
      "        int_test = int_test.drop('percentile',1)\n",
      "        int_test = int_test.drop('reg_ratio',1)\n",
      "        clf_proj.fit(int_train,train_labels)\n",
      "        scorings = cross_validation.cross_val_score(clf_proj,int_test,test_labels,cv=10)\n",
      "        mult_nb_score = np.mean(scorings)\n",
      "    scores.append(mult_nb_score)\n",
      "scores = np.array(scores)\n",
      "scores = 1 - scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(10,8))\n",
      "fig.set_facecolor('white')\n",
      "fs = 18\n",
      "plt.plot(interval,scores,'b--'); plt.xlabel('Buckets',fontsize=fs); plt.ylabel('Generalization Error',fontsize=fs); plt.title('Cross-Validated Generalization Error vs Discretization of MNB',fontsize=fs)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run through different C values to enforce harder vs softer margins.\n",
      "# C --> 0 enforces harder margins. \n",
      "\n",
      "C = np.linspace(0.01,1,50)\n",
      "scores = np.zeros((2,len(C)))\n",
      "i = 0\n",
      "for c in C:\n",
      "    log_reg = LogisticRegression(C=c)\n",
      "    svm_proj = svm.SVC(C=c)\n",
      "\n",
      "    # Fit for Log-Reg\n",
      "    scorings_log = cross_validation.cross_val_score(log_reg,train_data,train_labels,cv=10)\n",
      "    log_reg_score = np.mean(scorings_log)\n",
      "    \n",
      "    # Fit for SVM\n",
      "    scorings_svm = cross_validation.cross_val_score(svm_proj,train_data,train_labels,cv=10)\n",
      "    svm_proj_score = np.mean(scorings_svm)\n",
      "    \n",
      "    scores[:,i] = np.array([log_reg_score,svm_proj_score])\n",
      "    i = i + 1\n",
      "scores = 1 - scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(10,8))\n",
      "fig.set_facecolor('white')\n",
      "fs = 18\n",
      "plt.plot(C,scores[0,:],'r--',label='Linear Logistic Regression')\n",
      "plt.plot(C,scores[1,:],'k--',label='SVM')\n",
      "plt.xlabel('Regularization Constant',fontsize=fs); plt.ylabel('Generalization Error',fontsize=fs); plt.title('Cross-Validated Generalization Error vs Regularization Constant',fontsize=fs)\n",
      "plt.legend(prop={'size':fs-2})\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now run through a different number of estimators for RF\n",
      "N = np.arange(1,51,1)\n",
      "scores = []\n",
      "for n in N:\n",
      "    ran_forest = RandomForestClassifier(n_estimators=n)\n",
      "    scorings_rf = cross_validation.cross_val_score(ran_forest,train_data,train_labels,cv=10)\n",
      "    ran_forest_score = np.mean(scorings_rf)\n",
      "    scores.append(ran_forest_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = 1-np.array(scores)\n",
      "fig = plt.figure(figsize=(10,8))\n",
      "fig.set_facecolor('white')\n",
      "fs = 16\n",
      "plt.plot(N,scores,'g--',label='Random Forest')\n",
      "plt.xlabel('Number of Decision Trees',fontsize=fs); plt.ylabel('Generalization Error',fontsize=fs); plt.title('Cross-Validated Generalization Error vs Number of Decision Trees',fontsize=fs)\n",
      "plt.legend(prop={'size':fs-2})\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(scores==min(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "(array([43, 45]),)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}