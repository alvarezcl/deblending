{
 "metadata": {
  "name": "",
  "signature": "sha256:a056f2a2e9fea9623d54fa6f740154edc51024b958e6ddd8ef02b759e9ed2651"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import svm\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "import pandas as pd\n",
      "import compute_stats as cs\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.gridspec as Gridspec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the test data\n",
      "test_data = pd.read_csv('test.csv')\n",
      "test_data = test_data.drop('Unnamed: 0',1)\n",
      "test_labels = test_data['label']\n",
      "test_labels[test_labels==1] = 0; test_labels[test_labels>1] = 1\n",
      "test_data = test_data.drop('label',1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the training data\n",
      "train_data = pd.read_csv('training.csv')\n",
      "train_data = train_data.drop('Unnamed: 0',1)\n",
      "train_labels = train_data['label']\n",
      "train_labels[train_labels==1] = 0; train_labels[train_labels>1] = 1\n",
      "train_data = train_data.drop('label',1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert the test and training data into integers for multinomialNB\n",
      "interval = np.arange(250,1250,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interval"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_proj = MultinomialNB()\n",
      "\n",
      "scores = []\n",
      "i = 0\n",
      "for num in interval:\n",
      "    # Fit to training data and test on test data for MNB\n",
      "    int_test = cs.convert_to_integers(pd.DataFrame.copy(test_data),num)\n",
      "    int_train = cs.convert_to_integers(pd.DataFrame.copy(train_data),num)\n",
      "    drop = True\n",
      "    if drop:\n",
      "        int_train = int_train.drop('intensity_r',1)\n",
      "        int_train = int_train.drop('percentile',1)\n",
      "        int_train = int_train.drop('reg_ratio',1)\n",
      "        int_test = int_test.drop('intensity_r',1)\n",
      "        int_test = int_test.drop('percentile',1)\n",
      "        int_test = int_test.drop('reg_ratio',1)\n",
      "        clf_proj.fit(int_train,train_labels)\n",
      "        mult_nb_score = clf_proj.score(int_test,test_labels)\n",
      "    scores.append(mult_nb_score)\n",
      "scores = np.array(scores)\n",
      "scores = 1 - scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(10,8))\n",
      "fig.set_facecolor('white')\n",
      "fs = 20\n",
      "plt.plot(interval,scores,'k--'); plt.xlabel('Buckets',fontsize=fs); plt.ylabel('Generalization Error',fontsize=fs); plt.title('Generalization Error vs Discretization of MNB')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}